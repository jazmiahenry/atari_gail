{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f15500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharpCosSim2D(tf.keras.layers.Layer):\n",
    "    \"\"\"Model built based on sharpened cosine similarity logic.\"\"\"\n",
    "    \n",
    "    def __init__(self, kernel_size = 1, units = 32):\n",
    "        super(SharpCosSim2D, self).__init__()\n",
    "        self.units = units\n",
    "        self.kernel_size = kernel_size\n",
    "    \n",
    "    def build(self, input_shape = (28, 28, 1)):\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        self.output_y = math.ceil(self.input_shape[1]/ 1)\n",
    "        self.output_x = math.ceil(self.input_shape[2]/ 1)\n",
    "        self.flat_size = self.output_x * self.output_y\n",
    "        self.channels = self.input_shape[3]\n",
    "        \n",
    "        self.w = self.add_weight(\n",
    "            shape=(1, self.channels * tf.square(self.kernel_size), self.units),\n",
    "            initializer = tf.keras.initializers.GlorotNormal(),\n",
    "            trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer= \"zeros\", trainable=True)\n",
    "\n",
    "        self.p = self.add_weight(\n",
    "            shape=(self.units,), initializer= \"ones\", trainable=True)\n",
    "\n",
    "        self.q = self.add_weight(\n",
    "            shape=(1,), initializer= \"zeros\", trainable=True)\n",
    "        \n",
    "    def l2_normal(self, x, axis=None, epsilon=1e-12):\n"  #code inspired by Raphael Pisoni: https://www.rpisoni.dev/posts/cossim-convolution/, 
    "        square_sum = tf.reduce_sum(tf.square(x), axis, keepdims=True)\n",
    "        x_inv_norm = tf.sqrt(tf.maximum(square_sum, epsilon))\n",
    "        return x_inv_norm\n",
    "\n",
    "    def forward(self, x):\n",
    "        return tf.nn.sigmoid(x) * tf.nn.softplus(x)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        self.stack = lambda x: x\n",
    "        x = self.stack(inputs)\n",
    "        x = tf.reshape(x, (-1, self.flat_size, self.channels * tf.square(self.kernel_size)))\n",
    "        x_norm = (self.l2_normal(x, axis=2))\n",
    "        w_norm = (self.l2_normal(self.w, axis=1))\n",
    "        x = tf.matmul(x / x_norm, self.w / w_norm)\n",
    "        sign = tf.sign(x)\n",
    "        x = tf.abs(x) + 1e-12\n",
    "        x = tf.pow(x  + tf.square(self.b), self.forward(self.p))\n",
    "        x = sign * x\n",
    "        x = tf.reshape(x, (-1, self.output_y, self.output_x, self.units))\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
